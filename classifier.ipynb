{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0z2DCYU0DPnHLWEU9xzMK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manuflores/fishing_classification_project/blob/main/classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q numpy pandas matplotlib seaborn geopy scikit-learn xgboost"
      ],
      "metadata": {
        "id": "PjHtrT6Z4kgm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mpA40Yc94ikv"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Fishing classification using Scikit-learn.\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from geopy.distance import geodesic\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, learning_curve\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "def create_time_windowed_data(df: pd.DataFrame, window_size: int = 10) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Create time-windowed data for feature engineering.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    - df (pd.DataFrame): Input dataframe.\n",
        "    - window_size (int): Size of the time window.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    - pd.DataFrame: Dataframe with time-windowed features.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    feature_cols = ['speed', 'course', 'latitude', 'longitude']\n",
        "    for i in range(1, window_size + 1):\n",
        "        for col in feature_cols:\n",
        "            df[f\"{col}_t-{i}\"] = df.groupby('mmsi')[col].shift(i)\n",
        "    return df.dropna().reset_index(drop=True)\n",
        "\n",
        "def haversine_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n",
        "    \"\"\"\n",
        "    Compute great-circle distance (in km) between two lat/lon points.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    - lat1 (float): Latitude of the first point.\n",
        "    - lon1 (float): Longitude of the first point.\n",
        "    - lat2 (float): Latitude of the second point.\n",
        "    - lon2 (float): Longitude of the second point.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    - float: Distance in meters.\n",
        "    \"\"\"\n",
        "    if pd.notnull(lat1) and pd.notnull(lat2):\n",
        "        return geodesic((lat1, lon1), (lat2, lon2)).m\n",
        "    return 0\n",
        "\n",
        "def compute_vessel_distances(group: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compute distance for each vessel's movement history.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    - group (pd.DataFrame): Grouped dataframe for a single vessel.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    - pd.DataFrame: Dataframe with computed distances.\n",
        "    \"\"\"\n",
        "    latitudes = group['latitude'].values\n",
        "    longitudes = group['longitude'].values\n",
        "    distances = [0]  # First entry has no previous point to compare to\n",
        "\n",
        "    for i in range(1, len(latitudes)):\n",
        "        dist = haversine_distance(latitudes[i-1], longitudes[i-1], latitudes[i], longitudes[i])\n",
        "        distances.append(dist)\n",
        "\n",
        "    group['distance'] = distances\n",
        "    return group\n",
        "\n",
        "def compute_distance_for_all_vessels(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Apply distance computation to each vessel separately.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    - df (pd.DataFrame): Input dataframe.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    - pd.DataFrame: Dataframe with computed distances for all vessels.\n",
        "    \"\"\"\n",
        "    return df.groupby('mmsi', group_keys=False).apply(compute_vessel_distances)\n",
        "\n",
        "def compute_advanced_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compute advanced features for the dataset.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    - df (pd.DataFrame): Input dataframe.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    - pd.DataFrame: Dataframe with advanced features.\n",
        "    \"\"\"\n",
        "    df['hour'] = df['ts_pos_utc'].dt.hour\n",
        "    df['weekday'] = df['ts_pos_utc'].dt.weekday\n",
        "    df['season'] = df['ts_pos_utc'].dt.month % 12 // 3  # 0: Winter, 1: Spring, 2: Summer, 3: Fall\n",
        "    df['time_delta'] = df.groupby('mmsi')['ts_pos_utc'].diff().dt.total_seconds().fillna(0)\n",
        "\n",
        "    df['speed_diff'] = df.groupby('mmsi')['speed'].diff().fillna(0)\n",
        "    df['acceleration'] = df['speed_diff'] / df['time_delta'].replace(0, np.nan)  # Avoid division by zero\n",
        "    df['acceleration'] = df['acceleration'].fillna(0)\n",
        "    df['jerk'] = df.groupby('mmsi')['acceleration'].diff().fillna(0)\n",
        "\n",
        "    window_size = 10\n",
        "    feature_cols = ['speed', 'course', 'acceleration']\n",
        "    for col in feature_cols:\n",
        "        df[f'{col}_mean'] = df.groupby('mmsi')[col].rolling(window_size, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "        df[f'{col}_std'] = df.groupby('mmsi')[col].rolling(window_size, min_periods=1).std().reset_index(level=0, drop=True)\n",
        "        df[f'{col}_min'] = df.groupby('mmsi')[col].rolling(window_size, min_periods=1).min().reset_index(level=0, drop=True)\n",
        "        df[f'{col}_max'] = df.groupby('mmsi')[col].rolling(window_size, min_periods=1).max().reset_index(level=0, drop=True)\n",
        "\n",
        "    df['circular_variance'] = df.groupby('mmsi')['course'].rolling(10).apply(\n",
        "        lambda x: np.var(np.sin(np.radians(x))) + np.var(np.cos(np.radians(x))), raw=True\n",
        "    ).reset_index(level=0, drop=True)\n",
        "    return df\n",
        "\n",
        "def one_hot_encode_weekday(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    One-hot encode the weekday column.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    - df (pd.DataFrame): Input dataframe.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    - pd.DataFrame: Dataframe with one-hot encoded weekday.\n",
        "    \"\"\"\n",
        "    encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
        "    encoded = encoder.fit_transform(df[['weekday']])\n",
        "    df_encoded = pd.DataFrame(encoded, columns=[f\"weekday_{i}\" for i in range(1, 7)], index=df.index)\n",
        "    return pd.concat([df.drop(columns=['weekday']), df_encoded], axis=1)\n",
        "\n",
        "def add_speed_cluster(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Add speed cluster feature using KMeans clustering.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    - df (pd.DataFrame): Input dataframe.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    - pd.DataFrame: Dataframe with speed cluster feature.\n",
        "    \"\"\"\n",
        "    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "    df['speed_cluster'] = kmeans.fit_predict(df[['speed']])\n",
        "    return df\n",
        "\n",
        "def add_previous_fishing_status(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Add previous fishing status feature.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    - df (pd.DataFrame): Input dataframe.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    - pd.DataFrame: Dataframe with previous fishing status feature.\n",
        "    \"\"\"\n",
        "    df['previous_fishing'] = df.groupby('mmsi')['fishing'].shift(1).fillna(0).astype(int)\n",
        "    return df\n",
        "\n",
        "def perform_model_selection(models: dict, X: pd.DataFrame, y: np.ndarray, cv_folds: int = 5) -> dict:\n",
        "    \"\"\"\n",
        "    Perform K-Fold cross-validation on multiple models and compare their performance.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    - models (dict): Dictionary of models to evaluate.\n",
        "    - X (pd.DataFrame): Feature matrix.\n",
        "    - y (np.ndarray): Target variable.\n",
        "    - cv_folds (int): Number of folds in Stratified K-Fold cross-validation.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    - dict: A dictionary containing mean accuracy and standard deviation for each model.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    kfold = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    for name, model in models.items():\n",
        "        scores = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
        "        results[name] = (scores.mean(), scores.std())\n",
        "        print(f\"{name} - Cross-validation Accuracy: {scores.mean():.4f} Â± {scores.std():.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def plot_logistic_regression_coefficients(model: LogisticRegression, feature_names: pd.Index) -> None:\n",
        "    \"\"\"\n",
        "    Plot coefficients of a trained Logistic Regression model.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    - model (LogisticRegression): Trained Logistic Regression model.\n",
        "    - feature_names (pd.Index): Feature names.\n",
        "    \"\"\"\n",
        "    coefs = model.coef_.flatten()\n",
        "    coef_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefs}).sort_values(by='Coefficient')\n",
        "    print(f\"Top negative features LogReg:{coef_df.head(5)}\")\n",
        "    print(f\"Top positive features LogReg:{coef_df.tail(5)}\")\n",
        "\n",
        "    coef_df = coef_df[np.abs(coef_df.Coefficient.values) > .5]\n",
        "\n",
        "    plt.figure(figsize=(3, 4))\n",
        "    sns.barplot(x='Coefficient', y='Feature', data=coef_df, palette='coolwarm')\n",
        "    plt.title(\"Logistic Regression Coefficients\")\n",
        "    plt.yticks(fontsize=8)\n",
        "    plt.axvline(x=0, color='black', linestyle='--')\n",
        "    plt.show()\n",
        "\n",
        "def plot_feature_importance_rf(model: RandomForestClassifier, feature_names: pd.Index) -> None:\n",
        "    \"\"\"\n",
        "    Plot feature importance from a trained RandomForest model.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    - model (RandomForestClassifier): Trained RandomForest model.\n",
        "    - feature_names (pd.Index): Feature names.\n",
        "    \"\"\"\n",
        "    importances = model.feature_importances_\n",
        "    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values(by='Importance', ascending=False)\n",
        "    print(f\"Top features RF:{importance_df.head(10)}\")\n",
        "\n",
        "    plt.figure(figsize=(3, 5))\n",
        "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(20), palette='viridis')\n",
        "    plt.yticks(fontsize=8)\n",
        "    plt.title(\"Random Forest Feature Importance\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrices(models: dict, X_test: np.ndarray, y_test: np.ndarray) -> None:\n",
        "    \"\"\"\n",
        "    Plot confusion matrices for all trained models.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    - models (dict): Dictionary of trained models.\n",
        "    - X_test (np.ndarray): Test feature matrix.\n",
        "    - y_test (np.ndarray): Test target variable.\n",
        "    \"\"\"\n",
        "    for name, model in models.items():\n",
        "        y_pred = model.predict(X_test)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not Fishing\", \"Fishing\"])\n",
        "\n",
        "        plt.figure(figsize=(3, 3))\n",
        "        disp.plot(cmap='Blues', values_format='d')\n",
        "        plt.title(f\"Confusion Matrix - {name}\")\n",
        "        plt.show()\n",
        "\n",
        "def visualize_all(models: dict, X_test: np.ndarray, y_test: np.ndarray, feature_names: pd.Index, df: pd.DataFrame) -> None:\n",
        "    \"\"\"\n",
        "    Run all visualizations for interpretability analysis.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    - models (dict): Dictionary of trained models.\n",
        "    - X_test (np.ndarray): Test feature matrix.\n",
        "    - y_test (np.ndarray): Test target variable.\n",
        "    - feature_names (pd.Index): Feature names.\n",
        "    - df (pd.DataFrame): Input dataframe.\n",
        "    \"\"\"\n",
        "    print(\"Generating Logistic Regression Coefficients Plot...\")\n",
        "    if \"Logistic Regression\" in models:\n",
        "        plot_logistic_regression_coefficients(models['Logistic Regression'], feature_names)\n",
        "\n",
        "    print(\"Generating Random Forest Feature Importance Plot...\")\n",
        "    if \"Random Forest\" in models:\n",
        "        plot_feature_importance_rf(models['Random Forest'], feature_names)\n",
        "\n",
        "    print(\"Generating Confusion Matrices...\")\n",
        "    plot_confusion_matrices(models, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Add a code snippet for importing data from Drive\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vV9j68F5IA5",
        "outputId": "b88b22eb-99ca-431b-8ace-fc58612c9184"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### ============== DATA PREPROCESSING & TRAINING ============== ###\n",
        "print(\"Starting classification script...\")\n",
        "file_path = \"drive/MyDrive/trawlers.parquet\"\n",
        "\n",
        "\n",
        "df = pd.read_parquet(file_path)\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "df.drop(columns=\"vessel_class\", inplace=True)# all are trawlers\n",
        "\n",
        "clf_cols = list(set(df.columns) - set((\"mmsi\", \"ts_pos_utc\", \"fishing\")))\n",
        "\n",
        "### ============== EVALUATE BASELINE MODEL =====================\n",
        "\n",
        "# Select features and target variable\n",
        "X = df[clf_cols]\n",
        "y = df['fishing'].values.astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = log_reg.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Baseline model: Logistic Regression using {clf_cols} columns.\")\n",
        "print(f\"Accuracy with baselinemodel: {accuracy:.3f}\")\n",
        "print(\"Classification report\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cjw5jNHD53eB",
        "outputId": "dc05a55f-da4f-4924-cf1e-66d1a773b77b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting classification script...\n",
            "Baseline model: Logistic Regression using ['longitude', 'speed', 'latitude', 'course'] columns.\n",
            "Accuracy with baselinemodel: 0.568\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.84      0.70     33802\n",
            "           1       0.36      0.14      0.20     21481\n",
            "\n",
            "    accuracy                           0.57     55283\n",
            "   macro avg       0.48      0.49      0.45     55283\n",
            "weighted avg       0.51      0.57      0.51     55283\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### ============== FEATURE ENGINEERING ============== ###\n",
        "\n",
        "# Convert timestamp column to datetime format\n",
        "df['ts_pos_utc'] = pd.to_datetime(df['ts_pos_utc'])\n",
        "df = df.sort_values(by=[\"mmsi\", \"ts_pos_utc\"])\n",
        "df = create_time_windowed_data(df)\n",
        "df = compute_distance_for_all_vessels(df)\n",
        "df = compute_advanced_features(df)\n",
        "df = one_hot_encode_weekday(df)\n",
        "df = add_speed_cluster(df)\n",
        "df = df[~df.isnull().any(axis=1)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F31RQtI58Nk",
        "outputId": "265f4cbb-9f92-4633-90d6-dab5b3b666cd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-f40e687beade>:97: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return df.groupby('mmsi', group_keys=False).apply(compute_vessel_distances)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['mmsi', 'ts_pos_utc', 'fishing'])\n",
        "y = df['fishing'].values.astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42, stratify=y)\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "### ============== MODEL TRAINING ============== ###\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, oob_score=True),\n",
        "    \"XGBoost\": XGBClassifier(n_estimators=100, eval_metric='logloss'),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, learning_rate=0.1)\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"{name} - Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    if name == \"Random Forest\":\n",
        "        print(f\"OOB Score: {model.oob_score_:.4f}\")\n",
        "\n",
        "# Perform model selection across all models\n",
        "model_selection_results = perform_model_selection(models, X, y)\n",
        "visualize_all(models, X_test, y_test, X.columns, df)\n",
        "\n",
        "print(\"Script finished successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTecvaqk4xoq",
        "outputId": "63e072c6-9269-46d6-ed20-a86ec4e57f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Accuracy: 0.8578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QCwzRMc35-sg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}